{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIwO7Xm9gZul0WG0L1ModE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhnidh/Assessment-of-Fruit-Quality-using-Hyperspectral-Imaging-with-the-help-of-Deep-learning/blob/main/vggNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLph3tzKmBu3"
      },
      "outputs": [],
      "source": [
        "#importing library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pathlib\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.image as mpimg\n",
        "from numpy import *\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading images from path\n",
        "DATADIR = 'D:/archivefruit/fruits-360_dataset/fruits-360/Training'\n",
        "CATEGORIES = [\"Apple Braeburn\",\"Avocado\",\"Banana\",\"Blueberry\",\"Guava\",\"Kiwi\",\"Orange\"]\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path,img))\n",
        "        #,cv2.IMREAD_GRAYSCALE\n",
        "        plt.imshow(img_array)\n",
        "        plt.show()\n",
        "        break\n",
        "   # break"
      ],
      "metadata": {
        "id": "W8d7DkiumEMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building our training data\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:  # do fruits\n",
        "\n",
        "        path = os.path.join(DATADIR,category)  # create path to fruits\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 ,1,2,3,4,5,6) different number donate different category of fruit\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image per fruits\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "                training_data.append([new_array, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "image_count = len(training_data)"
      ],
      "metadata": {
        "id": "XxHVADyfmEOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_count)"
      ],
      "metadata": {
        "id": "L4IAbIvRmETK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle the dataset\n",
        "random.shuffle(training_data)"
      ],
      "metadata": {
        "id": "orRvHK-7mEVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in training_data[:10]:\n",
        "    print(sample[1])"
      ],
      "metadata": {
        "id": "2zyN8imLmEZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 100\n",
        "batch_size = 100\n",
        "img_height = 100\n",
        "img_width = 100"
      ],
      "metadata": {
        "id": "rJE40-0YmEbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning labels and features\n",
        "X =[]\n",
        "y =[]\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
      ],
      "metadata": {
        "id": "qeku7a7MmEf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating own model\n",
        "#Normalising X and converting labels to categorical data\n",
        "X = X.astype('float32')\n",
        "X /= 255\n",
        "Y = np_utils.to_categorical(y,7)\n",
        "print(Y[100])\n",
        "print(shape(Y))"
      ],
      "metadata": {
        "id": "f85p10CNmEhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "print(type(X))"
      ],
      "metadata": {
        "id": "qRwgbKrhmEl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array(y)\n",
        "print(type(y))"
      ],
      "metadata": {
        "id": "Lf3jQ2sQmEo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split X and Y for use in CNN\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)"
      ],
      "metadata": {
        "id": "y1HId1GYmjhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define compare and train the CNN model\n",
        "batch_size = 128\n",
        "nb_classes =7\n",
        "nb_epochs = 5\n",
        "img_rows, img_columns = 100, 100\n",
        "img_channel = 3\n",
        "nb_filters = 384\n",
        "nb_pool = 4\n",
        "nb_conv = 5"
      ],
      "metadata": {
        "id": "ptHUPn_OmjoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(96, (3,3), padding='same', activation=tf.nn.relu,input_shape=(100, 100, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=3),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=3),\n",
        "    tf.keras.layers.Conv2D(384, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=3),\n",
        "    tf.keras.layers.Conv2D(384, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=3),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(7,  activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "k2preF2lmjs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "IkJcZ2ANmju-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size = batch_size,verbose=1, epochs = 5,validation_split = 0.3, callbacks=[tf.keras.callbacks.CSVLogger('his.csv')]"
      ],
      "metadata": {
        "id": "MrGnfedfmjzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the Model\n",
        "history = pd.read_csv('his.csv')\n",
        "history.head()"
      ],
      "metadata": {
        "id": "ZafqlgZYmj1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(19,6))\n",
        "plt.subplot(131)\n",
        "plt.plot(history.epoch, history.loss, label=\"loss\")\n",
        "plt.plot(history.epoch, history.val_accuracy, label=\"val_accuracy\")\n",
        "plt.xlabel('loss')\n",
        "plt.ylabel('val_accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "hliE-Oflmj52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy and Score of model\n",
        "score = model.evaluate(X_test, y_test, verbose = 1 )\n",
        "print(\"Test Score: \", score[0])\n",
        "print(\"Test accuracy: \", score[1]*100,'%')"
      ],
      "metadata": {
        "id": "iGGzOGQRm5pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#observing its classification report and confusion matrix\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "#predict\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred=np.argmax(y_pred,axis=1)"
      ],
      "metadata": {
        "id": "z7uZkFkym5s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get classification report\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "oEJFnNkfm5yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get confusion matrix\n",
        "print(confusion_matrix(y_pred,y_test))"
      ],
      "metadata": {
        "id": "FSlcCBgim51Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_data = tf.keras.preprocessing.image_dataset_from_directory( path, validation_split=0.2, subset='training', seed=42, image_size=(img_height, img_width), batch_size=batch_size )"
      ],
      "metadata": {
        "id": "q66Hwu-SnJgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensorflow image classification"
      ],
      "metadata": {
        "id": "maONVVWgm58u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**import numpy as np import matplotlib.pyplot as plt import os import cv2 from tqdm import tqdm DATADIR = 'D:/archivefruit/fruits-360_dataset/fruits-360/Training' CATEGORIES = [\"Apple Braeburn\",\"Avocado\",\"Banana\",\"Blueberry\",\"Guava\",\"Kiwi\",\"Orange\"] for category in CATEGORIES: path = os.path.join(DATADIR, category) for img in os.listdir(path): img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE) plt.imshow(img_array, cmap=\"gray\") plt.show() break break**\n",
        "\n",
        "IMG_SIZE = 100\n",
        "\n",
        "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) plt.imshow(new_array, cmap='gray') plt.show()\n",
        "\n",
        "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) plt.imshow(new_array, cmap='gray') plt.show()\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data(): for category in CATEGORIES: # do fruits\n",
        "\n",
        "    path = os.path.join(DATADIR,category)  # create path to fruits\n",
        "    class_num = CATEGORIES.index(category)  # get the classification  (0 ,1,2,3,4,5,6). 0=dog 1=cat\n",
        "\n",
        "    for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "            training_data.append([new_array, class_num])  # add this to our training_data\n",
        "        except Exception as e:  # in the interest in keeping the output clean...\n",
        "            pass\n",
        "        #except OSError as e:\n",
        "        #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "        #except Exception as e:\n",
        "        #    print(\"general exception\", e, os.path.join(path,img))\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "print(len(training_data))\n",
        "\n",
        "print(len(training_data))\n",
        "\n",
        "import random random.shuffle(training_data)\n",
        "\n",
        "for sample in training_data[:10]: print(sample[1])\n",
        "\n",
        "#**creating own model**\n",
        "X = [] y = []\n",
        "\n",
        "for features,label in training_data: X.append(features) y.append(label)\n",
        "\n",
        "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "#**We can always load it in to our current script, or a totally new one by doing:**\n",
        "import pickle\n",
        "\n",
        "pickle_out = open(\"X.pickle\",\"wb\") pickle.dump(X, pickle_out) pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\",\"wb\") pickle.dump(y, pickle_out) pickle_out.close()\n",
        "\n",
        "pickle_in = open(\"X.pickle\",\"rb\") X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"y.pickle\",\"rb\") y = pickle.load(pickle_in)\n",
        "\n",
        "#**at 16,Let's save this data, so that we don't need to keep calculating it every time we want to play with the neural network model:**\n",
        "import pickle\n",
        "\n",
        "pickle_out = open(\"X.pickle\",\"wb\") pickle.dump(X, pickle_out) pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\",\"wb\") pickle.dump(y, pickle_out) pickle_out.close() We can always load it in to our current script, or a totally new one by doing:\n",
        "\n",
        "pickle_in = open(\"X.pickle\",\"rb\") X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"y.pickle\",\"rb\") y = pickle.load(pickle_in)\n",
        "\n",
        "#**Now that we've got out dataset, we're ready to cover convolutional neural networks and implement one with our data for classification.**"
      ],
      "metadata": {
        "id": "Aez00bpxnPvP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8lTPA27m6Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJahMsvim6Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_D41bTlamkBL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}